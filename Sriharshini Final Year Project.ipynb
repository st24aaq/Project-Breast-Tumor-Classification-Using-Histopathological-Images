{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  **Breast Tumor Classification Using Histopathological Images**\n",
        "\n",
        "##  **Introduction**\n",
        "Breast cancer is one of the most prevalent and life-threatening diseases among women worldwide.  \n",
        "Early and accurate diagnosis using histopathological images can significantly improve treatment outcomes.  \n",
        "\n",
        "This project aims to develop a **Convolutional Neural Network (CNN)** capable of classifying **benign vs malignant** tumor tissue images using the **BreakHis dataset**.  \n",
        "\n",
        "###  **Research Questions**\n",
        "1. Can CNN models accurately classify benign vs malignant tumor tissue images?\n",
        "2. Which visual features (texture, shape, patterns) are most influential, and can explainability methods such as **Grad-CAM** highlight them?\n",
        "3. How does model performance vary across magnification levels (200× and 400×), and can models generalize across magnifications?\n",
        "\n",
        "###  **Dataset Information**\n",
        "- **Name:** BreakHis – Breast Cancer Histopathological Database  \n",
        "- **Source:** [Mendeley Data – BreakHis Dataset](https://data.mendeley.com/datasets/jxwvdwhpc2/1)  \n",
        "- **Contributors:** Mayke Pereira et al., Instituto Federal de Educação, Ciência e Tecnologia do Espírito Santo, Brazil  \n",
        "- **Data Type:** RGB images (224 × 224 px) of breast-tumor tissues at magnifications 40×, 100×, 200×, 400×  \n",
        "- **Labels:** Benign (0) / Malignant (1)\n"
      ],
      "metadata": {
        "id": "lrb0yksv21hK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup and Dataset Download**"
      ],
      "metadata": {
        "id": "WGrMuQ5_39e8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlGPSDwzzwzk"
      },
      "outputs": [],
      "source": [
        "!apt-get install wget -q\n",
        "!wget -O breakhis.zip \"https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/jxwvdwhpc2-1.zip\"\n",
        "!unzip -q breakhis.zip -d /content/breakhis_dataset\n",
        "\n",
        "import os\n",
        "base_dir = \"/content/breakhis_dataset\"\n",
        "print(\" Dataset downloaded and extracted at:\", base_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  UNZIP INNER DATASET ARCHIVE\n",
        "\n",
        "\n",
        "inner_zip = \"/content/breakhis_dataset/BreakHis - Breast Cancer Histopathological Database/dataset_cancer_v1.zip\"\n",
        "extract_dir = \"/content/breakhis_dataset/final_dataset\"\n",
        "\n",
        "# Unzip the nested archive\n",
        "!unzip -q \"$inner_zip\" -d \"$extract_dir\"\n",
        "\n",
        "# Verify extraction\n",
        "import os\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    print(root, \"->\", len(files), \"files\")\n",
        "    break\n",
        "\n",
        "print(\" Inner dataset extracted successfully at:\", extract_dir)\n"
      ],
      "metadata": {
        "id": "wDsVN4us4gq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **Libraries and Initial Inspection**\n",
        "We’ll import TensorFlow and Keras for model development, and Matplotlib / Seaborn for visual analysis.  \n",
        "Let’s verify the folder structure and preview the dataset hierarchy.\n"
      ],
      "metadata": {
        "id": "z_aDmsAc4DLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import cv2\n",
        "magnification = \"200X\"  # choose among '40X', '100X', '200X', '400X'\n",
        "\n",
        "base_dir = f\"/content/breakhis_dataset/final_dataset/dataset_cancer_v1/classificacao_binaria/{magnification}\"\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    print(root, \"->\", len(files), \"files\")\n",
        "    break\n",
        "\n",
        "print(f\" Using magnification level: {magnification}\")"
      ],
      "metadata": {
        "id": "FPYSsI-v4FRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **Exploratory Data Analysis (EDA)**\n",
        "Before training the CNN, we examine the data distribution and visualize sample images from both classes.\n",
        "\n",
        "Key Objectives:\n",
        "- Check for balance between benign and malignant classes.  \n",
        "- View random samples for texture and color differences.  \n",
        "- Confirm image dimensions and quality.\n"
      ],
      "metadata": {
        "id": "Gzx8s70I5NT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count images per class\n",
        "class_counts = {'benign': 0, 'malignant': 0}\n",
        "for subdir, _, files in os.walk(base_dir):\n",
        "    if 'benign' in subdir.lower():\n",
        "        class_counts['benign'] += len(files)\n",
        "    elif 'malignant' in subdir.lower():\n",
        "        class_counts['malignant'] += len(files)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()), palette=\"coolwarm\")\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vyCLPiuF5LSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "# Initialize counters\n",
        "class_counts = {'benign': 0, 'malignant': 0}\n",
        "\n",
        "# Loop through dataset folders and count files\n",
        "for subdir, _, files in os.walk(base_dir):\n",
        "    if 'benign' in subdir.lower():\n",
        "        class_counts['benign'] += len(files)\n",
        "    elif 'malignant' in subdir.lower():\n",
        "        class_counts['malignant'] += len(files)\n",
        "\n",
        "# Print results neatly\n",
        "print(f\" Image Count Summary for {magnification} Magnification\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Benign Images   : {class_counts['benign']:,}\")\n",
        "print(f\"Malignant Images: {class_counts['malignant']:,}\")\n",
        "print(f\"Total Images    : {class_counts['benign'] + class_counts['malignant']:,}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Optional — Display as DataFrame\n",
        "import pandas as pd\n",
        "df_counts = pd.DataFrame.from_dict(class_counts, orient='index', columns=['Image_Count'])\n",
        "display(df_counts)\n"
      ],
      "metadata": {
        "id": "pkGXXEF46kum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Define base paths for both magnifications\n",
        "base_path = \"/content/breakhis_dataset/final_dataset/dataset_cancer_v1/classificacao_binaria\"\n",
        "magnifications = [\"200X\", \"400X\"]\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Loop over magnifications and count files\n",
        "for mag in magnifications:\n",
        "    mag_dir = os.path.join(base_path, mag)\n",
        "    class_counts = {'benign': 0, 'malignant': 0}\n",
        "\n",
        "    for subdir, _, files in os.walk(mag_dir):\n",
        "        if 'benign' in subdir.lower():\n",
        "            class_counts['benign'] += len(files)\n",
        "        elif 'malignant' in subdir.lower():\n",
        "            class_counts['malignant'] += len(files)\n",
        "\n",
        "    results[mag] = class_counts\n",
        "\n",
        "# Convert to DataFrame for nice display\n",
        "df = pd.DataFrame(results).T\n",
        "df['Total'] = df['benign'] + df['malignant']\n",
        "\n",
        "# Display results\n",
        "print(\"IMAGE COUNT SUMMARY — 200X vs 400X MAGNIFICATION\")\n",
        "print(\"-\" * 60)\n",
        "display(df)\n",
        "\n",
        "# Print formatted summary\n",
        "for mag in magnifications:\n",
        "    print(f\" {mag} Magnification:\")\n",
        "    print(f\"   Benign Images   : {results[mag]['benign']:,}\")\n",
        "    print(f\"   Malignant Images: {results[mag]['malignant']:,}\")\n",
        "    print(f\"   Total Images    : {results[mag]['benign'] + results[mag]['malignant']:,}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "hZjAEz-c7IQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  COUNT AND PLOT IMAGES FOR 200X AND 400X MAGNIFICATIONS\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define base path\n",
        "base_path = \"/content/breakhis_dataset/final_dataset/dataset_cancer_v1/classificacao_binaria\"\n",
        "magnifications = [\"200X\", \"400X\"]\n",
        "\n",
        "# Count images\n",
        "results = {}\n",
        "for mag in magnifications:\n",
        "    mag_dir = os.path.join(base_path, mag)\n",
        "    class_counts = {'Benign': 0, 'Malignant': 0}\n",
        "    for subdir, _, files in os.walk(mag_dir):\n",
        "        if 'benign' in subdir.lower():\n",
        "            class_counts['Benign'] += len(files)\n",
        "        elif 'malignant' in subdir.lower():\n",
        "            class_counts['Malignant'] += len(files)\n",
        "    results[mag] = class_counts\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(results).T\n",
        "df['Total'] = df['Benign'] + df['Malignant']\n",
        "\n",
        "# Print summary\n",
        "print(\" IMAGE COUNT SUMMARY — 200X vs 400X MAGNIFICATION\")\n",
        "print(\"-\" * 60)\n",
        "df\n"
      ],
      "metadata": {
        "id": "0SH4ivog7VWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP — PLOT SIDE-BY-SIDE BARS FOR 200X & 400X\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Prepare data (reuse df from previous cell)\n",
        "df_melted = df[['Benign', 'Malignant']].reset_index().melt(\n",
        "    id_vars='index', var_name='Class', value_name='Count'\n",
        ")\n",
        "df_melted.rename(columns={'index': 'Magnification'}, inplace=True)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(\n",
        "    data=df_melted,\n",
        "    x='Magnification',\n",
        "    y='Count',\n",
        "    hue='Class',\n",
        "    palette=['#66b3ff', '#ff6666'],\n",
        "    dodge=True\n",
        ")\n",
        "\n",
        "plt.title(\"Benign vs Malignant Image Counts — 200X vs 400X\", fontsize=13)\n",
        "plt.xlabel(\"Magnification Level\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.legend(title=\"Class\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Also show total comparison (optional)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.barplot(x=df.index, y=df['Total'], palette='pastel')\n",
        "plt.title(\"Total Images per Magnification\")\n",
        "plt.xlabel(\"Magnification Level\")\n",
        "plt.ylabel(\"Total Images\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CBmY8EHK700V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  DISPLAY SAMPLE IMAGES FROM 200X AND 400X DATASETS\n",
        "\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Define base paths for both magnifications\n",
        "base_path = \"/content/breakhis_dataset/final_dataset/dataset_cancer_v1/classificacao_binaria\"\n",
        "magnifications = [\"200X\", \"400X\"]\n",
        "\n",
        "# Prepare list to store samples (label, magnification, path)\n",
        "sample_paths = []\n",
        "\n",
        "for mag in magnifications:\n",
        "    mag_dir = os.path.join(base_path, mag)\n",
        "    for label in ['benign', 'malignant']:\n",
        "        for root, _, files in os.walk(mag_dir):\n",
        "            if label in root.lower() and files:\n",
        "                # randomly pick one image per class per magnification\n",
        "                sample_paths.append((label, mag, os.path.join(root, random.choice(files))))\n",
        "                break\n",
        "\n",
        "\n",
        "# Plot samples\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i, (label, mag, path) in enumerate(sample_paths):\n",
        "    img = Image.open(path)\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"{label.capitalize()} — {mag}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle(\"Sample Images from 200X and 400X Magnifications\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MMlcrmmf5bZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================\n",
        "# STEP — RGB COLOR INTENSITY HISTOGRAMS FOR 200X & 400X\n",
        "# =============================================================\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os, random\n",
        "\n",
        "# Define base path\n",
        "base_path = \"/content/breakhis_dataset/final_dataset/dataset_cancer_v1/classificacao_binaria\"\n",
        "magnifications = [\"200X\", \"400X\"]\n",
        "\n",
        "# Function to plot RGB histogram for an image\n",
        "def plot_rgb_hist(image_path, title, subplot_index):\n",
        "    img = cv2.imread(image_path)\n",
        "    colors = ('b', 'g', 'r')\n",
        "    plt.subplot(2, 2, subplot_index)\n",
        "    for i, col in enumerate(colors):\n",
        "        hist = cv2.calcHist([img], [i], None, [256], [0, 256])\n",
        "        plt.plot(hist, color=col)\n",
        "    plt.title(title, fontsize=9)\n",
        "    plt.xlim([0, 256])\n",
        "    plt.xlabel(\"Pixel Value\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "# Collect random images: 1 benign + 1 malignant from each magnification\n",
        "sample_images = []\n",
        "for mag in magnifications:\n",
        "    mag_dir = os.path.join(base_path, mag)\n",
        "    for label in ['benign', 'malignant']:\n",
        "        for root, _, files in os.walk(mag_dir):\n",
        "            if label in root.lower() and files:\n",
        "                random_img = os.path.join(root, random.choice(files))\n",
        "                sample_images.append((label, mag, random_img))\n",
        "                break\n",
        "\n",
        "# Plot histograms\n",
        "plt.figure(figsize=(10, 6))\n",
        "for idx, (label, mag, path) in enumerate(sample_images):\n",
        "    plot_rgb_hist(path, f\"{label.capitalize()} — {mag}\", idx + 1)\n",
        "\n",
        "plt.suptitle(\"RGB Color Intensity Distributions — 200X vs 400X\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FZUrvLlO6Uwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training and Evaluation"
      ],
      "metadata": {
        "id": "W76PEC_KFQ5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os"
      ],
      "metadata": {
        "id": "KHPOtlUHFOmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Set your dataset path exactly as shown in your folder\n",
        "data_dir = \"/content/breakhis_dataset/final_dataset/dataset_cancer_v1/classificacao_binaria/200X\"\n",
        "print(os.listdir(data_dir))  # should show ['benign', 'malignant']\n",
        "\n"
      ],
      "metadata": {
        "id": "SBe6Py3DFZlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "id": "GcDevd_yF1nE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(base_model):\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "yG_Oc_bMGCLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "vgg_model = build_model(vgg_base)\n",
        "\n",
        "history_vgg = vgg_model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "m9U_9jLBGGXJ",
        "outputId": "883d9f3c-3cc9-43b5-a6eb-8d9480c05f43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m20/51\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m12:45\u001b[0m 25s/step - accuracy: 0.5747 - loss: 0.7046"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "resnet_model = build_model(resnet_base)\n",
        "\n",
        "history_resnet = resnet_model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "90Szy_0UGJ1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eff_base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "eff_model = build_model(eff_base)\n",
        "\n",
        "history_eff = eff_model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "iGMe0Z-IGNsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, data, model_name):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Evaluating Model: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Evaluate on validation data\n",
        "    val_loss, val_acc = model.evaluate(data, verbose=0)\n",
        "    print(f\"{model_name} - Validation Accuracy: {val_acc*100:.2f}%\")\n",
        "\n",
        "    # Get predictions\n",
        "    preds = model.predict(data, verbose=0)\n",
        "    y_pred = np.round(preds).astype(int).flatten()\n",
        "    y_true = data.classes\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=list(data.class_indices.keys())))\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=list(data.class_indices.keys()),\n",
        "                yticklabels=list(data.class_indices.keys()))\n",
        "    plt.title(f'{model_name} - Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "    return val_acc, precision, recall, f1\n",
        "\n",
        "\n",
        "#  Evaluate all models\n",
        "results = {}\n",
        "\n",
        "models = {\n",
        "    \"VGG16\": vgg_model,\n",
        "    \"ResNet50\": resnet_model,\n",
        "    \"EfficientNetB0\": eff_model\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    acc, prec, rec, f1 = evaluate_model(model, val_data, name)\n",
        "    results[name] = [acc, prec, rec, f1]\n",
        "\n",
        "#  Compare All Model Results\n",
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame(results, index=['Accuracy', 'Precision', 'Recall', 'F1-Score']).T\n",
        "print(\"\\n=== Overall Model Comparison ===\")\n",
        "display(results_df)\n",
        "\n",
        "results_df.plot(kind='bar', figsize=(8,5), title=\"Model Performance Comparison\", rot=0)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0,1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GhfFKHgWGSfc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}